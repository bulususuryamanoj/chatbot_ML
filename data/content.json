{
  "supervised learning": "Supervised learning is a type of machine learning where models are trained using labeled data.",
  "unsupervised learning": "Unsupervised learning finds hidden patterns in unlabeled datasets.",
  "classification": "Classification predicts categorical labels such as spam or not spam.",
  "regression": "Regression predicts continuous numeric values.",
  "gradient descent": "Gradient descent is an optimization algorithm used to minimize loss functions.",
  "learning rate": "Learning rate controls how much model weights are updated during training.",
  "feature scaling": "Feature scaling normalizes data to improve model performance.",
  "standardization": "Standardization rescales features to have mean zero and unit variance.",
  "normalization": "Normalization rescales values between 0 and 1.",
  "train test split": "Train-test split divides data into training and testing sets to evaluate models.",
  "hyperparameter tuning": "Hyperparameter tuning improves model performance by adjusting parameters.",
  "grid search": "Grid search tests multiple parameter combinations to find the best model settings.",
  "random search": "Random search randomly samples parameter combinations during tuning.",
  "decision boundary": "Decision boundary separates different classes in classification problems.",
  "ensemble learning": "Ensemble learning combines multiple models to improve accuracy.",
  "bagging": "Bagging reduces variance by training models on random subsets of data.",
  "boosting": "Boosting improves performance by focusing on previous errors.",
  "adaboost": "AdaBoost is an ensemble method that adjusts weights of misclassified samples.",
  "xgboost": "XGBoost is a powerful gradient boosting algorithm widely used in competitions.",
  "lightgbm": "LightGBM is a fast gradient boosting framework optimized for performance.",
  "catboost": "CatBoost is a boosting algorithm designed to handle categorical features well.",
  "naive bayes": "Naive Bayes is a probabilistic classifier based on Bayes theorem.",
  "log loss": "Log loss measures classification model performance based on probability predictions.",
  "mean squared error": "MSE measures average squared difference between predicted and actual values.",
  "root mean squared error": "RMSE is the square root of MSE and measures prediction error.",
  "mean absolute error": "MAE measures average absolute differences between predictions and actual values.",
  "r squared": "R-squared indicates how well regression predictions fit the data.",
  "multicollinearity": "Multicollinearity occurs when features are highly correlated.",
  "one hot encoding": "One-hot encoding converts categorical variables into binary columns.",
  "label encoding": "Label encoding converts categories into numeric labels.",
  "ordinal encoding": "Ordinal encoding assigns ordered numeric values to categories.",
  "pipeline": "A pipeline automates preprocessing and modeling steps in machine learning.",
  "scikit learn": "Scikit-learn is a Python library used for machine learning tasks.",
  "tensorflow": "TensorFlow is a deep learning framework developed by Google.",
  "pytorch": "PyTorch is an open-source deep learning framework popular for research.",
  "neural network": "A neural network is a model inspired by the human brain used in deep learning.",
  "activation function": "Activation functions introduce non-linearity into neural networks.",
  "relu": "ReLU is an activation function that outputs zero for negative inputs.",
  "sigmoid": "Sigmoid maps values between 0 and 1 and is used in binary classification.",
  "softmax": "Softmax converts outputs into probability distributions across classes.",
  "epoch": "An epoch is one complete pass through the training dataset.",
  "batch size": "Batch size defines how many samples are processed before updating weights.",
  "dropout": "Dropout prevents overfitting by randomly disabling neurons during training.",
  "confounding variable": "A confounding variable influences both independent and dependent variables.",
  "correlation": "Correlation measures the strength of relationship between variables.",
  "covariance": "Covariance indicates how two variables change together.",
  "heatmap": "A heatmap visualizes data intensity using colors.",
  "boxplot": "A boxplot shows data distribution using quartiles.",
  "scatter plot": "A scatter plot shows relationships between two numeric variables.",
  "line chart": "A line chart displays trends over time.",
  "pie chart": "A pie chart shows proportions of categories.",
  "window function": "SQL window functions perform calculations across rows related to the current row.",
  "primary key": "A primary key uniquely identifies each record in a table.",
  "foreign key": "A foreign key links one table to another.",
  "indexing": "Indexing improves database query performance.",
  "subquery": "A subquery is a query nested inside another SQL query.",
  "case statement": "CASE statement adds conditional logic in SQL queries.",
  "common table expression": "CTE simplifies complex SQL queries using temporary result sets.",
  "etl": "ETL stands for Extract, Transform, Load â€” a data integration process.",
  "data warehouse": "A data warehouse stores structured data for analytics.",
  "big data": "Big data refers to extremely large datasets requiring advanced processing tools.",
  "hadoop": "Hadoop is a framework for distributed storage and processing of big data.",
  "spark": "Apache Spark is a fast engine for large-scale data processing.",
  
"feature selection": "Feature selection involves choosing the most relevant input variables to improve model performance.",
"wrapper methods": "Wrapper methods evaluate subsets of features using a predictive model to select the best combination.",
"filter methods": "Filter methods use statistical tests to select important features before modeling.",
"embedded methods": "Embedded methods perform feature selection during model training.",
"dimensionality reduction": "Dimensionality reduction reduces the number of features while preserving important information.",
"pca": "Principal Component Analysis reduces feature dimensions by transforming data into principal components.",
"lda": "Linear Discriminant Analysis is used for dimensionality reduction and classification.",
"t-sne": "t-SNE is a technique used to visualize high-dimensional data in two or three dimensions.",
"k means clustering": "K-Means is an unsupervised algorithm that groups data into clusters based on similarity.",
"hierarchical clustering": "Hierarchical clustering builds nested clusters by merging or splitting data points.",
"dbscan": "DBSCAN is a density-based clustering algorithm that detects clusters and noise.",
"silhouette score": "Silhouette score measures how similar an object is to its own cluster compared to other clusters.",
"anomaly detection": "Anomaly detection identifies unusual patterns or outliers in data.",
"time series": "Time series analysis deals with data collected over time intervals.",
"arima": "ARIMA is a statistical model used for time series forecasting.",
"seasonality": "Seasonality refers to repeating patterns in time series data.",
"lag feature": "Lag features use previous time steps as input variables in forecasting models.",
"natural language processing": "NLP enables computers to understand and process human language.",
"tokenization": "Tokenization splits text into smaller units such as words or sentences.",
"stemming": "Stemming reduces words to their root form by removing suffixes.",
"lemmatization": "Lemmatization converts words to their base dictionary form.",
"tf idf": "TF-IDF measures how important a word is in a document relative to a collection of documents.",
"word embedding": "Word embeddings represent words as numerical vectors capturing semantic meaning.",
"cosine similarity": "Cosine similarity measures similarity between two vectors based on angle.",
"recommendation system": "Recommendation systems suggest items based on user preferences and behavior.",
"collaborative filtering": "Collaborative filtering recommends items based on similar user behavior.",
"content based filtering": "Content-based filtering recommends items similar to those a user liked before.",
"a b testing": "A/B testing compares two versions to determine which performs better.",
"data leakage": "Data leakage occurs when information from outside the training dataset influences the model unfairly.",
"class imbalance": "Class imbalance happens when some classes have significantly more samples than others.",
"smote": "SMOTE is a technique used to generate synthetic samples for minority classes.",
"early stopping": "Early stopping halts training when validation performance stops improving.",
"regularization": "Regularization prevents overfitting by adding penalties to large model weights.",
"l1 regularization": "L1 regularization adds absolute weight penalties and performs feature selection.",
"l2 regularization": "L2 regularization adds squared weight penalties to reduce model complexity.",
"kernel trick": "Kernel trick allows SVM to perform nonlinear classification using higher-dimensional mapping.",
"data pipeline": "A data pipeline automates the flow of data from ingestion to processing and analysis.",
"model deployment": "Model deployment makes trained models available for real-world use through APIs or applications.",
"api": "An API allows applications to communicate and exchange data programmatically.",
"flask": "Flask is a lightweight Python web framework used to build APIs and web apps.",
"docker": "Docker packages applications into containers for consistent deployment across environments.",
"mlops": "MLOps combines machine learning with DevOps practices to manage model lifecycle.",
"feature store": "A feature store is a centralized repository for managing and serving machine learning features.",
"data drift": "Data drift occurs when data distribution changes over time, affecting model performance.",
"concept drift": "Concept drift happens when the relationship between input and output variables changes."
}
